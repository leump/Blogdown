<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Language on Shixiang, Wang | 王诗翔</title>
    <link>/en/paradigm/language/</link>
    <description>Recent content in Language on Shixiang, Wang | 王诗翔</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/en/paradigm/language/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Visual World Paradigm</title>
      <link>/en/paradigm/language/visual-world-paradigm/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/en/paradigm/language/visual-world-paradigm/</guid>
      <description>1. A brief description 2. Recent Applications 3. References   1. A brief description This paradigm relies on two seminal work published by Cooper (1974) and by Tanenhaus, Spivey-Knowlton, Eberhard, &amp;amp; Sedivy (1995). In a typical eye tracking study using the visual world paradigm, participants’ eye movements to objects or pictures in the visual workspace are recorded via an eye tracker as the participant produces or comprehends a spoken language describing the concurrent visual world.</description>
    </item>
    
  </channel>
</rss>